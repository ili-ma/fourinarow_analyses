{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create params_with_metrics\n",
    "```\n",
    "input: paramsMatrix.csv\n",
    "output: params_with_metrics.csv\n",
    "```\n",
    "Add these columns to params matrix:\n",
    "- Feature drop rate\n",
    "- Heuristic quality\n",
    "- Planning depth\n",
    "- ELO rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from fourinarowfunctions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide the directory where the data is kept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read parameters and calculate feature drop rate and heuristic quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(direc + 'paramsMatrix.csv')\n",
    "df = df.drop(\"Unnamed: 0\", axis = 1)\n",
    "params = np.array([expand_params(r) for r in df.values[:,-10:].astype(float)])\n",
    "\n",
    "df['feature drop rate'] = params[:,-1]\n",
    "df['heuristic quality'] = np.apply_along_axis(get_heuristic_quality,1,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute planning depth on the cluster. First, export the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(direc + 'params.txt', params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a directory on the cluster and move params.txt into it. Edit the compute_planning_depth.sh shell script so that the directory is correct, and change the number of jobs to the number of lines in params.txt (in this case 370). Run the script, then zip the depth folder with ```zip -r depth.zip depth```, move it back to your local computer and unzip in the directory where paramsMatrix.csv is stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "depth = np.vstack([np.loadtxt(direc + f\"depth/depth_fourinarow-dev_{i // 5}_{i % 5 + 1}.txt\") for i in range(len(params))])\n",
    "df['planning depth'] = depth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Elo\n",
    "Run only one of the two cells below depending on how your game data is store. Then continue with the \"Finish adding elo\" section.\n",
    "\n",
    "## Matlabe style *.tsv\n",
    "Run the cell below only if you have *.tsv files in the format Matlab uses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 37 games from ../data/generated_games\\Age0Sub200_vs_Level110.tsv\n",
      "Loaded 37 games from ../data/generated_games\\Age0Sub200_vs_Level118.tsv\n",
      "Loaded 37 games from ../data/generated_games\\Age0Sub200_vs_Level92.tsv\n",
      "Loaded 37 games from ../data/generated_games\\Age1Sub117_vs_Level110.tsv\n",
      "Loaded 37 games from ../data/generated_games\\Age1Sub117_vs_Level118.tsv\n",
      "Loaded 37 games from ../data/generated_games\\Age1Sub117_vs_Level92.tsv\n",
      "Loaded 37 games from ../data/generated_games\\Age2Sub1099_vs_Level110.tsv\n",
      "Loaded 37 games from ../data/generated_games\\Age2Sub1099_vs_Level118.tsv\n",
      "Loaded 37 games from ../data/generated_games\\Age2Sub1099_vs_Level92.tsv\n",
      "Elo data for 9 subjects\n"
     ]
    }
   ],
   "source": [
    "games = load_tabular(direc + \"generated_games/*.tsv\")\n",
    "# create dataframe\n",
    "forEloData = []\n",
    "for game in games:\n",
    "    first_row = game.iloc[0]\n",
    "    name = first_row.player_name # Extract player name and opponent level\n",
    "    forEloData.append([name, name.split(\"_vs_\")[1], first_row.player_color.lower(), get_tabular_outcome(game)])\n",
    "forElo = pd.DataFrame(data = forEloData, columns = ['subject', 'level', 'user_color', 'outcome'])\n",
    "print(f\"Elo data for {len(pd.unique(forElo['subject']))} subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Psiturk style *.csv\n",
    "Run the cell below only if you have a *.csv from Psiturk (probably \"trialdata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = load_data(direc + \"trialdata.csv\")\n",
    "\n",
    "# Compute an array with 1 row for every game.\n",
    "# Columns are username, game nr, opponent category, opponent level, player color, result\n",
    "# The result column is 1 = player won, -1 = opponent won, 0 = draw\n",
    "def categoryHist(username, data):\n",
    "    table = np.empty([0,6])\n",
    "    category = 2\n",
    "    for event in data:\n",
    "        if event['event_type'] == 'user move':\n",
    "            color = event['event_info']['user_color']\n",
    "        if event['event_type'] == 'adjust level':\n",
    "            category = event['event_info']['category']\n",
    "        if event['event_type'] == 'end game':\n",
    "            result = event['event_info']['result']\n",
    "            resultCode = 1 if result == 'win' else -1 if result == 'opponent win' else 0\n",
    "            table = np.vstack((table, [username, event['event_info']['game_num'], int(category), event['event_info']['level'], color, resultCode]))\n",
    "    return table\n",
    "\n",
    "# create dataframe\n",
    "forEloData = np.empty([0,6]) \n",
    "for username, userdata in data.items():\n",
    "    forEloData = np.vstack((forEloData, categoryHist(username, userdata)))\n",
    "forElo = pd.DataFrame(data = forEloData, columns = ['subject', 'gameNumber', 'category', 'level', 'user_color', 'outcome'])\n",
    "forElo[\"outcome\"] = forElo[\"outcome\"].astype(int)\n",
    "print(f\"Elo data for {len(pd.unique(forElo['subject']))} subjects\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finish adding elo\n",
    "Run the cells below regardless of how you loaded your game data. From this cell down the processing of matlab and psiturk files is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert the forElo to an array with one row per game.\n",
    "# The columns are Black player ID, White player ID, Winner.\n",
    "# Player IDs are subject ID for the player color and level for an AI player.\n",
    "# Outcome is 1 = black player won, -1 = white player won, 0 = draw\n",
    "def to_pgn(row):\n",
    "    subject = row['subject'].split(':')[1] if \":\" in row['subject'] else row['subject']\n",
    "    level = str(row['level'])\n",
    "    return [subject, level, row['outcome']] if row['user_color']=='black' else [level, subject, -row['outcome']]\n",
    "results = [to_pgn(row) for _,row in forElo.iterrows()]\n",
    "create_bayeselo_input(results, direc + 'games.pgn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "bayeselo_direc = './'\n",
    "\n",
    "elo = run_bayeselo(bayeselo_direc,[direc + 'tournament_results_short.pgn', direc + 'games.pgn'])\n",
    "elo = {key : val for key,val in elo.items() if not key.isdigit()}\n",
    "df[\"elo\"] = df[\"subject\"].apply(lambda x: x.split(\":\")[1] if \":\" in x else x).map(elo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the metrics are in the datafrome now. Let's save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(direc + 'params_with_metrics.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
