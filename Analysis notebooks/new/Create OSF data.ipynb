{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as sts\n",
    "from matplotlib import rcParams,font_manager\n",
    "import os\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from fourinarowfunctions import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcParams['figure.figsize'] = (6,6) #figure size in inches\n",
    "rcParams['font.family'] = \"sans-serif\" \n",
    "rcParams['font.weight'] = \"roman\" \n",
    "rcParams['font.style'] = \"normal\" # not 100% sure what this does but it was recommended\n",
    "rcParams['font.size'] = 32 # not 100% sure what this does but it was recommended\n",
    "rcParams['pdf.fonttype'] = 42\n",
    "rcParams['axes.linewidth'] = 2 #thickness of the border\n",
    "rcParams['xtick.major.width'] = rcParams['axes.linewidth'] # make sure line widths are consistent\n",
    "rcParams['ytick.major.width'] = rcParams['axes.linewidth']\n",
    "rcParams['axes.spines.right'] = False #hides right border\n",
    "rcParams['axes.spines.top'] = False #hides top\n",
    "rcParams['legend.frameon'] = False #hides box around the legend\n",
    "rcParams['legend.fontsize'] = 18 #font size in pt\n",
    "rcParams['axes.labelsize'] = 32 \n",
    "rcParams['xtick.labelsize'] = 24\n",
    "rcParams['ytick.labelsize'] = rcParams['xtick.labelsize']\n",
    "rcParams['lines.linewidth'] = 3\n",
    "rcParams['xtick.major.size'] = 5\n",
    "rcParams['lines.markersize'] = 16\n",
    "rcParams['ytick.major.size'] = rcParams['xtick.major.size'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "direc = 'C:/Users/svo/Google Drive/Bas Games/Analysis/'\n",
    "osf_direc = 'C:/Users/svo/Documents/FourinarowData/OSF/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(direc + 'loglik_all_pickled.txt','rb') as f:\n",
    "    loglik_all = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "loglik_all = np.hstack(loglik_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'final'\n",
    "expt_names = ['hvh','gen','eye','learn1','learn2','learn3','tai1','tai2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names = ['pruning threshold','stopping probability','feature drop rate','lapse rate','active scaling constant',\n",
    "               'center weight','connected 2-in-a-row weight','unconnected 2-in-a-row weight','3-in-a-row weight',\n",
    "               '4-in-a-row weight']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=['final','final_nonoise','final_nodelta','final_noprune','final_notree','final_noact','final_no3',\n",
    "        'final_no2conn','final_nocenter','final_no4','final_no2unc',\n",
    "        'final_optweights','final_mcts_myopic','final_drop_tile','final_fixed_iters',\n",
    "        'final_fixed_depth','final_fixed_branch','final_weight_hvd','final_drop_hvd',\n",
    "        'final_triangle','final_drop_type','final_opp']\n",
    "\n",
    "model_names = ['Main model','No value noise','No feature drop','No pruning','No tree','No active scaling',\n",
    "               'No 3-in-a-row','No connected 2-in-a-row','No center','No 4-in-a-row',\n",
    "               'No unconnected 2-in-a-row','Optimal weights','MCTS',\n",
    "               'Tile dropping','Fixed iterations','Fixed depth','Fixed branching',\n",
    "               'Orientation-dependent weights','Orientation-dependent dropping','Triangle',\n",
    "               'Type-dependent dropping','Opponent scaling']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_names_models = [param_names,param_names,param_names[:2] + param_names[3:],param_names[1:],\n",
    "                     param_names[2:],param_names[:4] + param_names[5:],param_names[:8] + param_names[9:],\n",
    "                      param_names[:6] + param_names[7:],param_names[:5] + param_names[6:],param_names[:9],\n",
    "                      param_names[:7] + param_names[8:],param_names[:5],\n",
    "                      param_names[1:4] + ['exploration constant'] + param_names[4:],\n",
    "                      param_names[:2] + ['tile drop rate'] + param_names[3:],\n",
    "                      param_names[:1] + ['inverse iteration number'] + param_names[2:],\n",
    "                      param_names[:1] + ['depth'] + param_names[2:],\n",
    "                      ['branching factor'] + param_names[1:],       \n",
    "                      param_names[:4] + ['horizontal-vertical scaling','horizontal-diagonal scaling'] + param_names[4:],\n",
    "                      param_names[:2] + param_names[3:] + ['horizontal feature drop rate','vertical feature drop rate',\n",
    "                                                           'diagonal feature drop rate'],\n",
    "                      param_names + ['triangle weight'],\n",
    "                      param_names[:2] + param_names[3:] + ['connected 2-in-a-row drop rate','unconnected 2-in-a-row drop rate',\n",
    "                                                           '3-in-a-row drop rate','4-in-a-row drop rate'],\n",
    "                      param_names[:4] + ['opponent scaling constant'] + param_names[4:],\n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(i):\n",
    "    model = models[i]\n",
    "    model_name = model_names[i]\n",
    "    param_names_model = param_names_models[i]\n",
    "    loglik = loglik_all[i,:]\n",
    "    params = np.vstack([np.loadtxt(direc + 'Params/params_' + name + '_' + model + '_short.txt') for name in expt_names])\n",
    "    df = pd.DataFrame(params,columns=param_names_model)\n",
    "    df['log-likelihood'] = loglik\n",
    "    print(model,model_name)\n",
    "    print(param_names_model)\n",
    "    df['model'] = model_name\n",
    "    df['experiment'] = ['human-vs-human']*200 + ['generalization']*200 + ['eye tracking']*50 + ['learning']*750 + ['time pressure']*450\n",
    "    df['participant'] = np.hstack([np.repeat(range(n),5) for n in [40,40,10]] + [np.repeat(range(30),25)] + [np.repeat(range(30),15)])+1\n",
    "    df['cross-validation group']=np.tile(range(1,6),330)\n",
    "    df['session number'] = np.nan\n",
    "    df['time limit'] = np.nan\n",
    "    df.loc[df['experiment']=='learning','session number'] = np.tile(np.repeat(range(1,6),5),30).astype(int)\n",
    "    df.loc[df['experiment']=='time pressure','time limit'] = np.tile(np.repeat([5,10,20],5),30).astype(int)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final Main model\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_nonoise No value noise\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_nodelta No feature drop\n",
      "['pruning threshold', 'stopping probability', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_noprune No pruning\n",
      "['stopping probability', 'feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_notree No tree\n",
      "['feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_noact No active scaling\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_no3 No 3-in-a-row\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '4-in-a-row weight']\n",
      "final_no2conn No connected 2-in-a-row\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_nocenter No center\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'active scaling constant', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_no4 No 4-in-a-row\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight']\n",
      "final_no2unc No unconnected 2-in-a-row\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_optweights Optimal weights\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'active scaling constant']\n",
      "final_mcts_myopic MCTS\n",
      "['stopping probability', 'feature drop rate', 'lapse rate', 'exploration constant', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_drop_tile Tile dropping\n",
      "['pruning threshold', 'stopping probability', 'tile drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_fixed_iters Fixed iterations\n",
      "['pruning threshold', 'inverse iteration number', 'feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_fixed_depth Fixed depth\n",
      "['pruning threshold', 'depth', 'feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_fixed_branch Fixed branching\n",
      "['branching factor', 'stopping probability', 'feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_weight_hvd Orientation-dependent weights\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'horizontal-vertical scaling', 'horizontal-diagonal scaling', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n",
      "final_drop_hvd Orientation-dependent dropping\n",
      "['pruning threshold', 'stopping probability', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight', 'horizontal feature drop rate', 'vertical feature drop rate', 'diagonal feature drop rate']\n",
      "final_triangle Triangle\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight', 'triangle weight']\n",
      "final_drop_type Type-dependent dropping\n",
      "['pruning threshold', 'stopping probability', 'lapse rate', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight', 'connected 2-in-a-row drop rate', 'unconnected 2-in-a-row drop rate', '3-in-a-row drop rate', '4-in-a-row drop rate']\n",
      "final_opp Opponent scaling\n",
      "['pruning threshold', 'stopping probability', 'feature drop rate', 'lapse rate', 'opponent scaling constant', 'active scaling constant', 'center weight', 'connected 2-in-a-row weight', 'unconnected 2-in-a-row weight', '3-in-a-row weight', '4-in-a-row weight']\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(models)):\n",
    "    df = create_df(i)\n",
    "    df.to_csv(osf_direc + 'model_fits_' + name.lower().replace(' ','_') + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pruning threshold', 'stopping probability', 'feature drop rate',\n",
       "       'lapse rate', 'opponent scaling constant', 'active scaling constant',\n",
       "       'center weight', 'connected 2-in-a-row weight',\n",
       "       'unconnected 2-in-a-row weight', '3-in-a-row weight',\n",
       "       '4-in-a-row weight', 'log-likelihood', 'model', 'experiment',\n",
       "       'participant', 'cross-validation group', 'session number',\n",
       "       'time limit'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_binstring(x):\n",
    "    return \"{0:036b}\".format(x)\n",
    "\n",
    "def parse_line(line):\n",
    "    line = line.replace('alltrials','').replace('{','').replace('}','').replace(',',' ').replace('ULL','').strip().split()\n",
    "    line[0] = parse_binstring(int(line[0],0))\n",
    "    line[1] = parse_binstring(int(line[1],0))\n",
    "    line[2] = np.log2(int(line[2],0)).astype(int)\n",
    "    line[3] = line[3].capitalize()\n",
    "    line[4] = float(line[4])/1000\n",
    "    line[5] = int(line[5])+1\n",
    "    line[6] = int(line[6])\n",
    "    return line\n",
    "\n",
    "def load_data(expt_name,name):\n",
    "    with open(direc + '../Data/data_' + expt_name + '.cpp') as f:\n",
    "        lines = f.read().splitlines() \n",
    "        for i,line in enumerate(lines):\n",
    "            if 'alltrials{{{' in line:\n",
    "                start_line = i\n",
    "                break\n",
    "        for i,line in enumerate(lines):\n",
    "            if '}}' in line:\n",
    "                end_line = i\n",
    "                break\n",
    "        lines = [parse_line(line) for line in lines[start_line:end_line+1]]\n",
    "        df = pd.DataFrame(lines,columns=['black_pieces','white_pieces','move','color','response_time','participant','cross-validation group'])\n",
    "        if expt_name.endswith('2'):\n",
    "            df['participant']+=50\n",
    "        if expt_name.endswith('3'):\n",
    "            df['participant']+=100\n",
    "        df['experiment'] = name\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([load_data(expt_name,name) for expt_name,name in \n",
    "           zip(['hvh','gen','eye','learn1','learn2','learn3','tai1','tai2'],\n",
    "               ['human-vs-human','generalization','eye tracking'] + ['learning'] *3 + ['time pressure']*2)],\n",
    "               ignore_index=True)\n",
    "df.loc[df['experiment']=='time pressure','time limit'] = df[df['experiment']=='time pressure']['participant'].map(\n",
    "    lambda p: {0:5,1:10,2:20}[(p-1)%3])\n",
    "df.loc[df['experiment']=='learning','session number'] = df[df['experiment']=='learning']['participant'].map(\n",
    "    lambda p: (p-1)%5+1)\n",
    "df.loc[df['experiment']=='time pressure','participant'] = (df.loc[df['experiment']=='time pressure','participant']-1)//3+1\n",
    "df.loc[df['experiment']=='learning','participant'] = (df.loc[df['experiment']=='learning','participant']-1)//5+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(osf_direc + 'raw_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
