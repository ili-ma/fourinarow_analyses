{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create splits\n",
    "```\n",
    "input: trialdata.csv\n",
    "output: splits folder\n",
    "```\n",
    "Trialdata.csv is created by psiturk when you download the datafile. This is the experiment data collected by the task stored in ```Experiment code```\n",
    "\n",
    "The splits folder will contain a named folder per subject. Test data is filtered out by inspecting the user id. Incomplete data is filtered out by inspecting the number of finished games. These folders contain data that can be fitted to a model by running ```Model code/matlab wrapper/auto_fit.sh``` on it. After model fitting is complete you can create paramsMatrix further down in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"../data/trialdata.csv\"\n",
    "output_folder = \"../data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load trialdata and put it in a dictionary from user id to list of data\n",
    "def load_data(filename):\n",
    "    df = pd.read_csv(filename, header=None, names=['participant_id','i','ts','info'])\n",
    "    result = {}\n",
    "    for participant_id in df['participant_id'].unique():\n",
    "        # Skip debug data by filtering in name\n",
    "        if any(part in participant_id.lower() for part in [\"debug\", \"test\", \"noas\", \"null\"]):\n",
    "            print(\"drop \" + participant_id)\n",
    "            continue\n",
    "        events = [json.loads(e) for e in df[df['participant_id'] == participant_id]['info']]\n",
    "        result[participant_id] = sorted(events,key=lambda e:e['event_time'])\n",
    "    return result\n",
    "\n",
    "data_dict = load_data(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "#helper functions that encode boards as and moves as integers for the model fitting pipeline\n",
    "def encode_board(pieces):\n",
    "    return np.sum([2**i for i,p in enumerate(pieces) if p=='1']).astype(np.int64)\n",
    "\n",
    "def get_events_with_type(f, event_type):\n",
    "    return [e for e in f if e['event_type'].replace('_',' ') == event_type.replace('_', ' ')]\n",
    "\n",
    "# Make data more accessible\n",
    "def get_parsed_data(data):\n",
    "    nGames = len(get_events_with_type(data, 'end game'))\n",
    "    # A full task includes 37 games, but completing almost all of them is good enough\n",
    "    assert nGames >= 36, f\"user only finished {nGames} games\"\n",
    "    assert nGames <= 37, f\"user completed too many games? {nGames}\"\n",
    "    your_turn_events = get_events_with_type(data, 'your turn')\n",
    "    user_move_events = get_events_with_type(data, 'user move')\n",
    "    assert len(your_turn_events) == len(user_move_events), \"user quit in the middle of a turn\"\n",
    "    return [(e['event_info']['bp'], e['event_info']['wp'], e['event_info']['tile'],\n",
    "             e['event_info']['user_color'], (e['event_time'] - e_your_turn['event_time']) / 1000)\n",
    "            for e_your_turn, e in zip(your_turn_events, user_move_events) if \"bp\" in e[\"event_info\"]]\n",
    "\n",
    "def ensure_dir(dirname):\n",
    "    if not os.path.exists(dirname):\n",
    "        os.mkdir(dirname)\n",
    "\n",
    "def save_raw_splits(data_dict, root):\n",
    "    ensure_dir(root + '/raw/')\n",
    "    ensure_dir(root + '/splits/')\n",
    "    for username, data in data_dict.items():\n",
    "        print(f\"writing {username} {len(data)}\", end='\\r')\n",
    "        try:\n",
    "            parsed_data = get_parsed_data(data)\n",
    "        except AssertionError as e:\n",
    "            print(f\"Incomplete {username}: {e}\")\n",
    "            continue\n",
    "        filename = username.replace(\":\", \"-\")\n",
    "        with open(root + '/raw/' + filename + '.csv', 'w') as f:\n",
    "            df = pd.DataFrame([(encode_board(bp), encode_board(wp), c.lower().capitalize(), 2**m, rt, username.split(':')[0]) for bp,wp,m,c,rt in parsed_data])\n",
    "            f.write(df.to_csv(None, index=False, header=False, sep='\\t', line_terminator ='\\n')[:-1])\n",
    "        group = (5 * (np.random.permutation(len(parsed_data))/len(parsed_data))).astype(int) + 1\n",
    "        ensure_dir(root + '/splits/' + filename)\n",
    "        with open(root + '/splits/' + filename + '/data.csv', 'w') as f:\n",
    "            df = pd.DataFrame([(encode_board(bp),encode_board(wp), c.lower().capitalize(), 2**m, rt,g,username.split(':')[0]) for (bp,wp,m,c,rt), g in zip(parsed_data, group)])\n",
    "            f.write(df.to_csv(None, index = False, header=False, sep='\\t', line_terminator='\\n')[:-1])\n",
    "        for g in range(1,6):\n",
    "            with open(root + '/splits/' + filename + '/' + str(g) + '.csv', 'w') as f:\n",
    "                df = pd.DataFrame([(encode_board(bp), encode_board(wp), c.lower().capitalize(), 2**m, rt,g,username.split(':')[0]) for (bp,wp,m,c,rt), g in zip(parsed_data, group)])\n",
    "                f.write(df[df[5]==g].to_csv(None, index=False, header=False, sep='\\t', line_terminator='\\n')[:-1])\n",
    "    print(f\"Done{' ' * 40}\")\n",
    "\n",
    "save_raw_splits(data_dict, output_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create paramsMatrix\n",
    "```\n",
    "input: fitted parameters\n",
    "output: paramsMatrix.csv\n",
    "```\n",
    "The input structure is a root folder that contains folders with fitted parameters, like this:\n",
    "```\n",
    "data folder\n",
    " +- subject_id_1\n",
    " |  +- params1.csv\n",
    " |  +- params2.csv\n",
    " |  +- ...\n",
    " +- subject_id_2\n",
    " |  +- params1.csv\n",
    " ...\n",
    "```\n",
    "Use paramsMatrix.csv in the ```Calculate metrics and Elo``` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../data/splits\"\n",
    "output_file = \"../data/paramsMatrix.csv\"\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "parampattern = \"params(\\\\d+).csv\"\n",
    "\n",
    "lines = []\n",
    "num_subjects = 0\n",
    "for subject_id in os.listdir(data_folder):\n",
    "    subdir = os.path.join(data_folder, subject_id)\n",
    "    if not os.path.isdir(subdir):\n",
    "        # We're looking for directories only. Skip everything else\n",
    "        continue\n",
    "    num_subjects += 1\n",
    "    for filename in os.listdir(subdir):\n",
    "        filepath = os.path.join(subdir, filename)\n",
    "        match = re.match(parampattern, filename)\n",
    "        if not os.path.isfile(filepath) or not match:\n",
    "            # Skip any file that isn't a param*.csv file\n",
    "            continue\n",
    "        fold_number = match.group(1)\n",
    "        with open(filepath) as infile:\n",
    "            lines.append([subject_id.replace(\"-\",\":\"), int(fold_number), infile.readline().strip()])\n",
    "lines.sort()\n",
    "linecounter = 0\n",
    "with open(output_file, \"w\") as targetfile:\n",
    "    # Write the header\n",
    "    targetfile.write(\",subject,fold,\")\n",
    "    targetfile.write(\",\".join([str(item) for item in range(1,11)]))\n",
    "    targetfile.write(\"\\n\")\n",
    "    # Write content\n",
    "    for line in lines:\n",
    "        line.insert(0, linecounter)\n",
    "        targetfile.write(\",\".join([str(item) for item in line]))\n",
    "        targetfile.write(\"\\n\")\n",
    "        linecounter += 1\n",
    "print(f\"Found {num_subjects} subjects. Wrote {len(lines)} lines to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
